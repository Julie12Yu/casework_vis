"In the case Deyerler v. HireVue Inc., six Illinois residents filed a class action lawsuit against HireVue, a software vendor known for using AI in virtual job interviews, claiming violations of the Illinois Biometric Information Privacy Act (BIPA). The plaintiffs alleged that HireVue's software captured and collected their biometric information without proper consent during these interviews. The U.S. District Court for the Northern District of Illinois ruled that it had specific personal jurisdiction over HireVue due to its intentional actions of marketing software that recorded biometric data in Illinois. The court partially granted HireVue's motion to dismiss, allowing claims under several sections of BIPA related to retention policies and unauthorized biometric data capture to proceed, while dismissing claims regarding profit from biometric data due to insufficient allegations.",
"In the case Frasco v. Flo Health, Inc., the plaintiffs alleged that the Flo Period and Ovulation Tracker app secretly transmitted sensitive health data related to menstruation and pregnancy to third parties like Google and Meta using their software development kits (SDKs), despite assurances of privacy from Flo. The court granted class certification for the plaintiffsâ€™ claims under California's Confidentiality of Medical Information Act (CMIA), breach of contract, and intrusion upon seclusion, finding that the common issues in the case could be resolved on a classwide basis. The case highlights concerns over the integration of AI and automated systems in applications that handle sensitive personal information.",
"This case involves a multiparty litigation stemming from a data security breach at AshleyMadison.com, owned by Avid Dating Life, Inc. Plaintiffs allege that Avid failed to adequately protect their personal and financial information, marketed an ineffective 'Full Delete Removal' service, and used artificial intelligence bots to create misleading user profiles. A group of 42 plaintiffs sought to proceed anonymously to avoid public exposure of their sensitive information, fearing severe personal and professional repercussions. The court ruled that while the plaintiffs' privacy concerns were significant, the need for transparency in class representation necessitated that they disclose their identities to adequately represent the class.",
"In the case of Kemp v. Meta Platforms Inc., the plaintiff, a federal prisoner, filed a pro se civil complaint alleging that Meta unlawfully accessed and used his private electronic communications through its platforms (Facebook Messenger, WhatsApp, and Instagram) using artificial intelligence (AI). He claimed that Meta's AI, developed in 2017 and integrated further in 2018, monitored and intercepted his communications in violation of the Stored Communications Act and the Wiretap Act. The court granted Meta's motion to dismiss based on res judicata, as the plaintiff previously made similar claims in another lawsuit, which had been dismissed for failure to state a claim, and thus barred the current action without leave to amend.",
"In the case of In re TikTok, Inc. Consumer Privacy Litigation, TikTok faced allegations from plaintiffs that it unlawfully collected and profited from users' private information through its popular social media app, leading to a settlement of $92 million. The settlement included monetary relief for users, as well as injunctive measures to prohibit future privacy violations, particularly concerning TikTok's AI-driven data collection methods, which were claimed to harvest personal data without user consent.",
"In the case of Tate v. Chemed Corp., the court examined whether VITAS Healthcare's use of Invoca's call monitoring software violated California's privacy laws. Charmaine Tate alleged that her rights were infringed when Invoca recorded calls to VITAS without consent, classifying Invoca as a third party that utilized the data for its own purposes. The court ruled that because Invoca's software recorded and analyzed calls independently, it constituted a violation of California's Invasion of Privacy Act (CIPA). Consequently, VITAS could also be held liable for facilitating this unauthorized data collection.",
"In Mendell v. American Medical Response, Inc., the court evaluated a putative class action where plaintiff Michael Mendell alleged that AMR recorded calls without consent, violating the California Invasion of Privacy Act. AMR contested class certification, arguing that Mendell lacked a feasible method for class identification, particularly due to concerns over the reliability of AI transcription tools like IBM Watson, which raised HIPAA compliance issues. The court denied AMR's motion to strike evidence related to class identification, allowing for further discussion and a potential sur-reply addressing class identification methodologies, highlighting the role of AI in processing call records.",
"""Desiree Schmitt filed a lawsuit against SN Servicing Corporation following a data breach in late 2020 that compromised the personal information of over 170,000 individuals. The court granted in part and denied in part SNSC's motion to dismiss, allowing Schmitt to proceed with her negligence and unfair competition claims, while dismissing her invasion of privacy claim due to insufficient evidence of egregious conduct. The court also noted that Schmitt failed to plead specific violations under the unfair competition law's unlawful prong but permitted her to amend her complaint.",
"""In the case of Ogletree v. Cleveland State University, the plaintiff, Aaron Ogletree, challenged the university's remote testing policy that required students to conduct room scans of their surroundings before taking online exams, arguing it violated his Fourth Amendment rights. The court ruled in favor of Ogletree, finding that the room scans constituted unreasonable searches as they intruded upon the privacy of students in their homes. The decision highlighted the risks to constitutional rights presented by the university's approach, which involved the use of automated proctoring tools that monitor test-takers for potential cheating.",
"""In the case Naughton v. Amazon.com, Inc. et al., William Naughton, on behalf of himself and a class of employees, accused Amazon of collecting sensitive biometric data, specifically facial geometry scans, without consent as part of mandatory wellness checks during the COVID-19 pandemic, violating the Illinois Biometric Information Privacy Act (BIPA). The court denied Amazon's motion to dismiss, determining that Naughton provided sufficient allegations that Amazon actively collected and stored biometric data, thus meeting the statutory requirements. This case highlights concerns regarding privacy and consent in the use of biometric technologies, such as facial recognition, employed by automated systems in workplace safety protocols.",